{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.lib.io import file_io\n",
    "import argparse\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, Conv1D, Flatten\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from numpy import array, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as k\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import tag_constants, signature_constants\n",
    "from tensorflow.python.saved_model.signature_def_utils_impl import predict_signature_def\n",
    "\n",
    "import coremltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "epochs = 100\n",
    "\n",
    "batch_size = 200\n",
    "validation_split = 0.2\n",
    "\n",
    "# model parameters\n",
    "dropout = 0.2\n",
    "timesteps = 40\n",
    "timesteps_in_future = 20\n",
    "nodes_per_layer = 32\n",
    "filter_length = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_file='data_classes_4_squats_adjusted.csv', job_dir='leeeeeroooooyyyyyjeeeeeenkins', **args):\n",
    "    parameter_string = 'final_25_classes_4_squats_adjusted' + '_dropout_' + str(dropout) + '_timesteps_' + str(\n",
    "        timesteps) + '_timesteps_in_future_' + str(timesteps_in_future) + '_nodes_per_layer_' + str(\n",
    "        nodes_per_layer) + '_filter_length_' + str(filter_length)\n",
    "    if 'gs://' in job_dir:\n",
    "        logs_path = 'gs://exermotemachinelearningengine' + '/logs/' + parameter_string\n",
    "    else:\n",
    "        logs_path = '.' + '/logs/' + parameter_string\n",
    "    print('-----------------------')\n",
    "    print('Using train_file located at {}'.format(train_file))\n",
    "    print('Using logs_path located at {}'.format(logs_path))\n",
    "    print('-----------------------')\n",
    "\n",
    "    # load data\n",
    "    file_stream = file_io.FileIO(train_file, mode='r')\n",
    "    dataframe = read_csv(file_stream, header=0)\n",
    "    dataframe.fillna(0, inplace=True)\n",
    "    dataset = dataframe.values\n",
    "\n",
    "    X = dataset[:, [\n",
    "        #2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, # Device: xGravity, yGravity, zGravity, xAcceleration, yAcceleration, zAcceleration, pitch, roll, yaw, xRotationRate, yRotationRate, zRotationRate\n",
    "        2, 3, 4, 5, 6, 7, 8, 9, 10, 11  # xAcceleration, yAcceleration, zAcceleration, xRotationRate, yRotationRate, zRotationRate\n",
    "        # 14,15,16,17,                          # Right Hand: rssi, xAcceleration, yAcceleration, zAcceleration\n",
    "        # 18,19,20,21,                          # Left Hand: rssi, xAcceleration, yAcceleration, zAcceleration\n",
    "        # 22,23,24,25,                          # Right Foot: rssi, xAcceleration, yAcceleration, zAcceleration\n",
    "        # 26,27,28,29,                          # Left Foot: rssi, xAcceleration, yAcceleration, zAcceleration\n",
    "        # 30,31,32,33,                          # Chest: rssi, xAcceleration, yAcceleration, zAcceleration\n",
    "        # 34,35,36,37                           # Belly: rssi, xAcceleration, yAcceleration, zAcceleration\n",
    "    ]].astype(float)\n",
    "    y = dataset[:, 0]  # ExerciseType (Index 1 is ExerciseSubType)\n",
    "\n",
    "    # data parameters\n",
    "    data_dim = X.shape[1]\n",
    "    num_classes = len(set(y))\n",
    "\n",
    "    # scale X\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X = scaler.fit_transform(X)  # X*scaler.scale_+scaler.min_ (columnwise)\n",
    "    print('Multiplying each row in X elementwise: {}'.format(scaler.scale_))\n",
    "    print('Increasing each row in X elemtwise: {}'.format(scaler.min_))\n",
    "\n",
    "    # encode Y\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    encoded_y = encoder.transform(y)  # encoder.classes_\n",
    "    print('Hotencoding Y: {}'.format(encoder.classes_))\n",
    "    hot_encoded_y = np_utils.to_categorical(encoded_y)\n",
    "\n",
    "    # prepare data for LSTM\n",
    "    def create_LSTM_dataset(x, y, timesteps):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(x) - timesteps + 1):\n",
    "            dataX.append(x[i:i + timesteps, :])\n",
    "            dataY.append(y[i + timesteps - timesteps_in_future - 1, :])\n",
    "        return array(dataX), array(dataY)\n",
    "\n",
    "    X, hot_encoded_y = create_LSTM_dataset(X, hot_encoded_y, timesteps)\n",
    "\n",
    "    # define model\n",
    "    model = Sequential([\n",
    "        Conv1D(nodes_per_layer, filter_length, strides=2, activation='relu', input_shape=(timesteps, data_dim),\n",
    "               name='accelerations'),\n",
    "        Conv1D(nodes_per_layer, filter_length, strides=1, activation='relu'),\n",
    "        LSTM(nodes_per_layer, return_sequences=True),\n",
    "        LSTM(nodes_per_layer, return_sequences=False),\n",
    "        Dropout(dropout),\n",
    "        #Flatten(),\n",
    "        Dense(num_classes),\n",
    "        Activation('softmax', name='scores'),\n",
    "    ])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # define callbacks\n",
    "    callbacks = []\n",
    "\n",
    "    tensor_board = TensorBoard(log_dir=logs_path, histogram_freq=1, write_graph=False, write_images=False)\n",
    "    callbacks.append(tensor_board)\n",
    "\n",
    "    checkpoint_path = 'best_weights.h5'\n",
    "    checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks.append(checkpoint)\n",
    "\n",
    "    # train model\n",
    "    model.fit(X, hot_encoded_y,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_split=validation_split,\n",
    "              callbacks=callbacks\n",
    "              )\n",
    "\n",
    "    # load best checkpoint\n",
    "    model.load_weights('best_weights.h5')\n",
    "\n",
    "    # evaluate best model\n",
    "    def non_shuffling_train_test_split(X, y, test_size=validation_split):\n",
    "        i = int((1 - test_size) * X.shape[0]) + 1\n",
    "        X_train, X_test = split(X, [i])\n",
    "        y_train, y_test = split(y, [i])\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    _, X_test, _, y_test = non_shuffling_train_test_split(X, hot_encoded_y, test_size=validation_split)\n",
    "\n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    acc = scores[1]\n",
    "\n",
    "    # save model\n",
    "    model_h5_name = 'model_acc_' + str(acc) + '.h5'\n",
    "    model.save(model_h5_name)\n",
    "\n",
    "    # save model.h5 on to google storage\n",
    "    with file_io.FileIO(model_h5_name, mode='r') as input_f:\n",
    "        with file_io.FileIO(logs_path + '/' + model_h5_name, mode='w+') as output_f:\n",
    "            output_f.write(input_f.read())\n",
    "\n",
    "            # reset session\n",
    "            # Note: If this piece of code did help you to achieve your goal, please upvote my solution under:\n",
    "            # https://stackoverflow.com/questions/41959318/deploying-keras-models-via-google-cloud-ml/44232441#44232441\n",
    "            # Thank you so much :)\n",
    "    k.clear_session()\n",
    "    sess = tf.Session()\n",
    "    k.set_session(sess)\n",
    "\n",
    "    # disable loading of learning nodes\n",
    "    k.set_learning_phase(0)\n",
    "\n",
    "    # load model\n",
    "    model = load_model(model_h5_name)\n",
    "    config = model.get_config()\n",
    "    weights = model.get_weights()\n",
    "    new_Model = Sequential.from_config(config)\n",
    "    new_Model.set_weights(weights)\n",
    "\n",
    "    # export coreml model\n",
    "\n",
    "    coreml_model = coremltools.converters.keras.convert(new_Model, input_names=['accelerations'],\n",
    "                                                        output_names=['scores'])\n",
    "    model_mlmodel_name = 'model_acc_' + str(acc) + '.mlmodel'\n",
    "    coreml_model.save(model_mlmodel_name)\n",
    "\n",
    "    # save model.mlmodel on to google storage\n",
    "    with file_io.FileIO(model_mlmodel_name, mode='r') as input_f:\n",
    "        with file_io.FileIO(logs_path + '/' + model_mlmodel_name, mode='w+') as output_f:\n",
    "            output_f.write(input_f.read())\n",
    "\n",
    "            # export saved model\n",
    "            # Note: If this piece of code did help you to achieve your goal, please upvote my solution under:\n",
    "            # https://stackoverflow.com/questions/41959318/deploying-keras-models-via-google-cloud-ml/44232441#44232441\n",
    "            # Thank you so much :)\n",
    "    export_path = logs_path + \"/export\"\n",
    "    builder = saved_model_builder.SavedModelBuilder(export_path)\n",
    "\n",
    "    signature = predict_signature_def(inputs={'accelerations': new_Model.input},\n",
    "                                      outputs={'scores': new_Model.output})\n",
    "\n",
    "    with k.get_session() as sess:\n",
    "        builder.add_meta_graph_and_variables(sess=sess,\n",
    "                                             tags=[tag_constants.SERVING],\n",
    "                                             signature_def_map={\n",
    "                                                 signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature})\n",
    "        builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Using train_file located at ../MoviLabData/LEARNING_DATA/0503_total_data.csv\n",
      "Using logs_path located at ./logs/final_25_classes_4_squats_adjusted_dropout_0.2_timesteps_40_timesteps_in_future_20_nodes_per_layer_32_filter_length_3\n",
      "-----------------------\n",
      "Multiplying each row in X elementwise: [0.3834129  0.33094978 0.43548987 0.00535685 0.00461063 0.00225244\n",
      " 0.59090852 0.00416316 0.31833579 0.3183348 ]\n",
      "Increasing each row in X elemtwise: [ 0.55663203  0.53363229  0.34883845  0.49910175  0.37812764  0.46909765\n",
      " -0.16079866 -0.00163039  0.50000758  0.49999952]\n",
      "Hotencoding Y: ['pushup' 'situp' 'squat']\n",
      "WARNING:tensorflow:From /home/dldustn14/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dldustn14/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dldustn14/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dldustn14/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dldustn14/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "accelerations (Conv1D)       (None, 19, 32)            992       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 17, 32)            3104      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 17, 32)            8320      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 99        \n",
      "_________________________________________________________________\n",
      "scores (Activation)          (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 20,835\n",
      "Trainable params: 20,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/dldustn14/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dldustn14/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dldustn14/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 19226 samples, validate on 4807 samples\n",
      "WARNING:tensorflow:From /home/dldustn14/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:796: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dldustn14/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/dldustn14/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:856: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/100\n",
      "19226/19226 [==============================] - 7s 347us/step - loss: 0.2071 - acc: 0.9286 - val_loss: 1.3984 - val_acc: 0.6574\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.65737, saving model to best_weights.h5\n",
      "Epoch 2/100\n",
      "19226/19226 [==============================] - 5s 271us/step - loss: 0.0269 - acc: 0.9930 - val_loss: 1.4373 - val_acc: 0.6530\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.65737\n",
      "Epoch 3/100\n",
      "19226/19226 [==============================] - 5s 266us/step - loss: 0.0204 - acc: 0.9951 - val_loss: 1.8369 - val_acc: 0.5271\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.65737\n",
      "Epoch 4/100\n",
      "19226/19226 [==============================] - 5s 270us/step - loss: 0.0141 - acc: 0.9968 - val_loss: 1.8798 - val_acc: 0.5760\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.65737\n",
      "Epoch 5/100\n",
      "19226/19226 [==============================] - 5s 267us/step - loss: 0.0090 - acc: 0.9969 - val_loss: 3.8014 - val_acc: 0.3449\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.65737\n",
      "Epoch 6/100\n",
      "19226/19226 [==============================] - 5s 258us/step - loss: 0.0076 - acc: 0.9976 - val_loss: 1.9142 - val_acc: 0.5669\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.65737\n",
      "Epoch 7/100\n",
      "19226/19226 [==============================] - 5s 259us/step - loss: 0.0043 - acc: 0.9984 - val_loss: 0.9138 - val_acc: 0.6969\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.65737 to 0.69690, saving model to best_weights.h5\n",
      "Epoch 8/100\n",
      "19226/19226 [==============================] - 5s 263us/step - loss: 0.0052 - acc: 0.9982 - val_loss: 1.6956 - val_acc: 0.6461\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.69690\n",
      "Epoch 9/100\n",
      "19226/19226 [==============================] - 5s 256us/step - loss: 0.0044 - acc: 0.9985 - val_loss: 1.8444 - val_acc: 0.6170\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.69690\n",
      "Epoch 10/100\n",
      "19226/19226 [==============================] - 5s 258us/step - loss: 0.0063 - acc: 0.9983 - val_loss: 4.2325 - val_acc: 0.4419\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.69690\n",
      "Epoch 11/100\n",
      "19226/19226 [==============================] - 5s 264us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 3.3520 - val_acc: 0.5184\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.69690\n",
      "Epoch 12/100\n",
      "19226/19226 [==============================] - 5s 261us/step - loss: 0.0043 - acc: 0.9986 - val_loss: 3.9229 - val_acc: 0.5111\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.69690\n",
      "Epoch 13/100\n",
      "19226/19226 [==============================] - 5s 259us/step - loss: 0.0047 - acc: 0.9985 - val_loss: 2.2598 - val_acc: 0.6518\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.69690\n",
      "Epoch 14/100\n",
      "19226/19226 [==============================] - 5s 262us/step - loss: 0.0043 - acc: 0.9986 - val_loss: 4.2680 - val_acc: 0.4770\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.69690\n",
      "Epoch 15/100\n",
      "19226/19226 [==============================] - 5s 260us/step - loss: 0.0036 - acc: 0.9991 - val_loss: 2.2927 - val_acc: 0.6540\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.69690\n",
      "Epoch 16/100\n",
      "19226/19226 [==============================] - 5s 260us/step - loss: 0.0039 - acc: 0.9988 - val_loss: 2.7361 - val_acc: 0.6372\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.69690\n",
      "Epoch 17/100\n",
      "19226/19226 [==============================] - 5s 255us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 2.8771 - val_acc: 0.6050\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.69690\n",
      "Epoch 18/100\n",
      "19226/19226 [==============================] - 5s 261us/step - loss: 0.0022 - acc: 0.9992 - val_loss: 3.3635 - val_acc: 0.6264\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.69690\n",
      "Epoch 19/100\n",
      "19226/19226 [==============================] - 5s 270us/step - loss: 0.0028 - acc: 0.9990 - val_loss: 2.9349 - val_acc: 0.6083\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.69690\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19226/19226 [==============================] - 5s 273us/step - loss: 0.0024 - acc: 0.9993 - val_loss: 4.6580 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.69690\n",
      "Epoch 21/100\n",
      "19226/19226 [==============================] - 5s 275us/step - loss: 0.0039 - acc: 0.9991 - val_loss: 3.6025 - val_acc: 0.5912\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.69690\n",
      "Epoch 22/100\n",
      "19226/19226 [==============================] - 5s 272us/step - loss: 0.0022 - acc: 0.9993 - val_loss: 4.2200 - val_acc: 0.5569\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.69690\n",
      "Epoch 23/100\n",
      "19226/19226 [==============================] - 5s 273us/step - loss: 0.0020 - acc: 0.9993 - val_loss: 3.7152 - val_acc: 0.5921\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.69690\n",
      "Epoch 24/100\n",
      "19226/19226 [==============================] - 5s 273us/step - loss: 0.0027 - acc: 0.9989 - val_loss: 2.6936 - val_acc: 0.6332\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.69690\n",
      "Epoch 25/100\n",
      "19226/19226 [==============================] - 5s 272us/step - loss: 0.0023 - acc: 0.9993 - val_loss: 3.2266 - val_acc: 0.6147\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.69690\n",
      "Epoch 26/100\n",
      "19226/19226 [==============================] - 5s 272us/step - loss: 0.0054 - acc: 0.9988 - val_loss: 2.8401 - val_acc: 0.6409\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.69690\n",
      "Epoch 27/100\n",
      "19226/19226 [==============================] - 5s 273us/step - loss: 0.0023 - acc: 0.9993 - val_loss: 2.0065 - val_acc: 0.6476\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.69690\n",
      "Epoch 28/100\n",
      "19226/19226 [==============================] - 5s 275us/step - loss: 0.0032 - acc: 0.9990 - val_loss: 2.1232 - val_acc: 0.6480\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.69690\n",
      "Epoch 29/100\n",
      "19226/19226 [==============================] - 5s 273us/step - loss: 0.0016 - acc: 0.9994 - val_loss: 5.4324 - val_acc: 0.4920\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.69690\n",
      "Epoch 30/100\n",
      "19226/19226 [==============================] - 5s 270us/step - loss: 0.0024 - acc: 0.9993 - val_loss: 2.0030 - val_acc: 0.6788\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.69690\n",
      "Epoch 31/100\n",
      "19226/19226 [==============================] - 5s 272us/step - loss: 0.0027 - acc: 0.9992 - val_loss: 2.8305 - val_acc: 0.6434\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.69690\n",
      "Epoch 32/100\n",
      "19226/19226 [==============================] - 5s 272us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 4.2047 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.69690\n",
      "Epoch 33/100\n",
      "19226/19226 [==============================] - 5s 271us/step - loss: 0.0015 - acc: 0.9994 - val_loss: 1.4409 - val_acc: 0.7090\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.69690 to 0.70897, saving model to best_weights.h5\n",
      "Epoch 34/100\n",
      "19226/19226 [==============================] - 5s 272us/step - loss: 0.0022 - acc: 0.9994 - val_loss: 2.1402 - val_acc: 0.6674\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.70897\n",
      "Epoch 35/100\n",
      "19226/19226 [==============================] - 5s 277us/step - loss: 0.0027 - acc: 0.9994 - val_loss: 2.4555 - val_acc: 0.6694\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.70897\n",
      "Epoch 36/100\n",
      "19226/19226 [==============================] - 5s 272us/step - loss: 0.0019 - acc: 0.9992 - val_loss: 3.2032 - val_acc: 0.6449\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.70897\n",
      "Epoch 37/100\n",
      "19226/19226 [==============================] - 5s 270us/step - loss: 0.0016 - acc: 0.9994 - val_loss: 3.7803 - val_acc: 0.6022\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.70897\n",
      "Epoch 38/100\n",
      "19226/19226 [==============================] - 5s 282us/step - loss: 0.0016 - acc: 0.9996 - val_loss: 3.7797 - val_acc: 0.6264\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.70897\n",
      "Epoch 39/100\n",
      "19226/19226 [==============================] - 5s 283us/step - loss: 0.0022 - acc: 0.9993 - val_loss: 3.6814 - val_acc: 0.6045\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.70897\n",
      "Epoch 40/100\n",
      "19226/19226 [==============================] - 5s 282us/step - loss: 0.0012 - acc: 0.9995 - val_loss: 3.7998 - val_acc: 0.6549\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.70897\n",
      "Epoch 41/100\n",
      "19226/19226 [==============================] - 5s 281us/step - loss: 0.0025 - acc: 0.9994 - val_loss: 3.1322 - val_acc: 0.6476\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.70897\n",
      "Epoch 42/100\n",
      "19226/19226 [==============================] - 5s 282us/step - loss: 0.0040 - acc: 0.9990 - val_loss: 4.3131 - val_acc: 0.6122\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.70897\n",
      "Epoch 43/100\n",
      "19226/19226 [==============================] - 5s 283us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 2.6678 - val_acc: 0.6813\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.70897\n",
      "Epoch 44/100\n",
      "19226/19226 [==============================] - 5s 283us/step - loss: 0.0017 - acc: 0.9994 - val_loss: 1.8116 - val_acc: 0.7079\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.70897\n",
      "Epoch 45/100\n",
      "19226/19226 [==============================] - 6s 289us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 3.5700 - val_acc: 0.5887\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.70897\n",
      "Epoch 46/100\n",
      "19226/19226 [==============================] - 6s 287us/step - loss: 0.0013 - acc: 0.9995 - val_loss: 4.5120 - val_acc: 0.5925\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.70897\n",
      "Epoch 47/100\n",
      "19226/19226 [==============================] - 5s 283us/step - loss: 0.0011 - acc: 0.9996 - val_loss: 1.8351 - val_acc: 0.7462\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.70897 to 0.74620, saving model to best_weights.h5\n",
      "Epoch 48/100\n",
      "19226/19226 [==============================] - 5s 283us/step - loss: 0.0032 - acc: 0.9992 - val_loss: 6.4920 - val_acc: 0.4595\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.74620\n",
      "Epoch 49/100\n",
      "19226/19226 [==============================] - 5s 282us/step - loss: 0.0021 - acc: 0.9994 - val_loss: 5.5794 - val_acc: 0.4907\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.74620\n",
      "Epoch 50/100\n",
      "19226/19226 [==============================] - 5s 271us/step - loss: 0.0017 - acc: 0.9995 - val_loss: 7.6574 - val_acc: 0.3306\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.74620\n",
      "Epoch 51/100\n",
      "19226/19226 [==============================] - 5s 284us/step - loss: 0.0012 - acc: 0.9995 - val_loss: 0.6052 - val_acc: 0.8563\n",
      "\n",
      "Epoch 00051: val_acc improved from 0.74620 to 0.85625, saving model to best_weights.h5\n",
      "Epoch 52/100\n",
      "19226/19226 [==============================] - 5s 284us/step - loss: 0.0036 - acc: 0.9989 - val_loss: 4.2334 - val_acc: 0.5827\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.85625\n",
      "Epoch 53/100\n",
      "19226/19226 [==============================] - 6s 286us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 3.2034 - val_acc: 0.6613\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.85625\n",
      "Epoch 54/100\n",
      "19226/19226 [==============================] - 5s 284us/step - loss: 0.0020 - acc: 0.9994 - val_loss: 4.0908 - val_acc: 0.6206\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.85625\n",
      "Epoch 55/100\n",
      "19226/19226 [==============================] - 6s 290us/step - loss: 0.0017 - acc: 0.9995 - val_loss: 2.9117 - val_acc: 0.6732\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.85625\n",
      "Epoch 56/100\n",
      "19226/19226 [==============================] - 6s 287us/step - loss: 0.0017 - acc: 0.9993 - val_loss: 4.8867 - val_acc: 0.5615\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.85625\n",
      "Epoch 57/100\n",
      "19226/19226 [==============================] - 5s 283us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 3.1695 - val_acc: 0.6586\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.85625\n",
      "Epoch 58/100\n",
      "19226/19226 [==============================] - 5s 285us/step - loss: 0.0014 - acc: 0.9995 - val_loss: 2.9167 - val_acc: 0.6857\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.85625\n",
      "Epoch 59/100\n",
      "19226/19226 [==============================] - 5s 283us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 3.0501 - val_acc: 0.6620\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.85625\n",
      "Epoch 60/100\n",
      "19226/19226 [==============================] - 5s 283us/step - loss: 0.0019 - acc: 0.9994 - val_loss: 5.1530 - val_acc: 0.5093\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.85625\n",
      "Epoch 61/100\n",
      "19226/19226 [==============================] - 5s 282us/step - loss: 0.0040 - acc: 0.9991 - val_loss: 3.7657 - val_acc: 0.5948\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.85625\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19226/19226 [==============================] - 5s 283us/step - loss: 0.0017 - acc: 0.9995 - val_loss: 3.7882 - val_acc: 0.6260\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.85625\n",
      "Epoch 63/100\n",
      "19226/19226 [==============================] - 5s 284us/step - loss: 9.4542e-04 - acc: 0.9996 - val_loss: 3.5677 - val_acc: 0.6447\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.85625\n",
      "Epoch 64/100\n",
      "19226/19226 [==============================] - 5s 284us/step - loss: 0.0022 - acc: 0.9994 - val_loss: 3.8011 - val_acc: 0.6172\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.85625\n",
      "Epoch 65/100\n",
      "19226/19226 [==============================] - 5s 284us/step - loss: 9.9333e-04 - acc: 0.9995 - val_loss: 4.4805 - val_acc: 0.5814\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.85625\n",
      "Epoch 66/100\n",
      "19226/19226 [==============================] - 6s 287us/step - loss: 0.0039 - acc: 0.9991 - val_loss: 4.8293 - val_acc: 0.5871\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.85625\n",
      "Epoch 67/100\n",
      "19226/19226 [==============================] - 6s 288us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 3.0951 - val_acc: 0.6595\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.85625\n",
      "Epoch 68/100\n",
      "19226/19226 [==============================] - 5s 282us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 4.7239 - val_acc: 0.5931\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.85625\n",
      "Epoch 69/100\n",
      "19226/19226 [==============================] - 5s 282us/step - loss: 0.0015 - acc: 0.9994 - val_loss: 4.2974 - val_acc: 0.6486\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.85625\n",
      "Epoch 70/100\n",
      "19226/19226 [==============================] - 5s 281us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 3.5012 - val_acc: 0.6821\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.85625\n",
      "Epoch 71/100\n",
      "19226/19226 [==============================] - 5s 284us/step - loss: 0.0011 - acc: 0.9996 - val_loss: 4.9748 - val_acc: 0.5548\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.85625\n",
      "Epoch 72/100\n",
      "19226/19226 [==============================] - 5s 282us/step - loss: 0.0011 - acc: 0.9995 - val_loss: 1.9417 - val_acc: 0.7880\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.85625\n",
      "Epoch 73/100\n",
      "19226/19226 [==============================] - 5s 284us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 2.5488 - val_acc: 0.6686\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.85625\n",
      "Epoch 74/100\n",
      "19226/19226 [==============================] - 5s 283us/step - loss: 0.0013 - acc: 0.9995 - val_loss: 3.1815 - val_acc: 0.6253\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.85625\n",
      "Epoch 75/100\n",
      "19226/19226 [==============================] - 5s 283us/step - loss: 0.0018 - acc: 0.9996 - val_loss: 5.0052 - val_acc: 0.5833\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.85625\n",
      "Epoch 76/100\n",
      "19226/19226 [==============================] - 5s 284us/step - loss: 0.0012 - acc: 0.9995 - val_loss: 2.4723 - val_acc: 0.6640\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.85625\n",
      "Epoch 77/100\n",
      "19226/19226 [==============================] - 5s 283us/step - loss: 0.0018 - acc: 0.9996 - val_loss: 4.6731 - val_acc: 0.6064\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.85625\n",
      "Epoch 78/100\n",
      "19226/19226 [==============================] - 5s 283us/step - loss: 0.0011 - acc: 0.9995 - val_loss: 5.2090 - val_acc: 0.5475\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.85625\n",
      "Epoch 79/100\n",
      "19226/19226 [==============================] - 5s 284us/step - loss: 0.0016 - acc: 0.9996 - val_loss: 3.2775 - val_acc: 0.6214\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.85625\n",
      "Epoch 80/100\n",
      "19226/19226 [==============================] - 5s 282us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 4.2161 - val_acc: 0.6137\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.85625\n",
      "Epoch 81/100\n",
      "19226/19226 [==============================] - 5s 283us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 3.2394 - val_acc: 0.6838\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.85625\n",
      "Epoch 82/100\n",
      "19226/19226 [==============================] - 5s 282us/step - loss: 8.0134e-04 - acc: 0.9997 - val_loss: 5.8649 - val_acc: 0.5280\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.85625\n",
      "Epoch 83/100\n",
      "19226/19226 [==============================] - 5s 286us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 4.3709 - val_acc: 0.6447\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.85625\n",
      "Epoch 84/100\n",
      "19226/19226 [==============================] - 5s 282us/step - loss: 0.0017 - acc: 0.9995 - val_loss: 5.1329 - val_acc: 0.6035\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.85625\n",
      "Epoch 85/100\n",
      "19226/19226 [==============================] - 5s 284us/step - loss: 9.4063e-04 - acc: 0.9997 - val_loss: 2.1266 - val_acc: 0.7491\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.85625\n",
      "Epoch 86/100\n",
      "19226/19226 [==============================] - 5s 283us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 2.7359 - val_acc: 0.6865\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.85625\n",
      "Epoch 87/100\n",
      "19226/19226 [==============================] - 5s 272us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 3.0757 - val_acc: 0.6950\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.85625\n",
      "Epoch 88/100\n",
      "19226/19226 [==============================] - 5s 284us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 3.9819 - val_acc: 0.6622\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.85625\n",
      "Epoch 89/100\n",
      "19226/19226 [==============================] - 5s 284us/step - loss: 6.2485e-04 - acc: 0.9997 - val_loss: 3.0618 - val_acc: 0.6867\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.85625\n",
      "Epoch 90/100\n",
      "19226/19226 [==============================] - 6s 286us/step - loss: 7.7878e-04 - acc: 0.9997 - val_loss: 4.1955 - val_acc: 0.6276\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.85625\n",
      "Epoch 91/100\n",
      "19226/19226 [==============================] - 5s 285us/step - loss: 8.7657e-04 - acc: 0.9997 - val_loss: 3.9235 - val_acc: 0.6699\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.85625\n",
      "Epoch 92/100\n",
      "19226/19226 [==============================] - 5s 285us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 4.4185 - val_acc: 0.6054\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.85625\n",
      "Epoch 93/100\n",
      "19226/19226 [==============================] - 5s 283us/step - loss: 9.1388e-04 - acc: 0.9996 - val_loss: 4.2426 - val_acc: 0.6607\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.85625\n",
      "Epoch 94/100\n",
      "19226/19226 [==============================] - 5s 285us/step - loss: 9.4453e-04 - acc: 0.9996 - val_loss: 5.2394 - val_acc: 0.6099\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.85625\n",
      "Epoch 95/100\n",
      "19226/19226 [==============================] - 5s 283us/step - loss: 9.8557e-04 - acc: 0.9996 - val_loss: 4.3818 - val_acc: 0.6058\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.85625\n",
      "Epoch 96/100\n",
      "19226/19226 [==============================] - 5s 283us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 4.4780 - val_acc: 0.6139\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.85625\n",
      "Epoch 97/100\n",
      "19226/19226 [==============================] - 5s 282us/step - loss: 0.0010 - acc: 0.9997 - val_loss: 3.5278 - val_acc: 0.6592\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.85625\n",
      "Epoch 98/100\n",
      "19226/19226 [==============================] - 5s 282us/step - loss: 8.3727e-04 - acc: 0.9998 - val_loss: 2.4040 - val_acc: 0.6984\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.85625\n",
      "Epoch 99/100\n",
      "19226/19226 [==============================] - 6s 287us/step - loss: 0.0011 - acc: 0.9996 - val_loss: 4.7455 - val_acc: 0.6187\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.85625\n",
      "Epoch 100/100\n",
      "19226/19226 [==============================] - 5s 285us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 2.6916 - val_acc: 0.6468\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.85625\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-53bb92226742>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \"\"\"\n\u001b[1;32m     19\u001b[0m     \u001b[0marguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'train_file'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'../MoviLabData/LEARNING_DATA/0503_total_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'job_dir'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'./'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-8ae591c97172>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_file, job_dir, **args)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_h5_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_h5_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutput_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0moutput_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m# reset session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    126\u001b[0m       \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     return self._prepare_value(\n\u001b[0;32m--> 128\u001b[0;31m         pywrap_tensorflow.ReadFromStream(self._read_buf, length))\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m   @deprecation.deprecated_args(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m_prepare_value\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_str_any\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    115\u001b[0m   \"\"\"\n\u001b[1;32m    116\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_text\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbytes_or_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_or_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbytes_or_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected binary or unicode string, got %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbytes_or_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Input Arguments\n",
    "    parser.add_argument(\n",
    "        '--train-file',\n",
    "        help='GCS or local paths to training data',\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--job-dir',\n",
    "        help='GCS location to write checkpoints and export models',\n",
    "        required=True\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    arguments = args.__dict__\n",
    "    print('trainfile & job dir arguments :',arguments)\n",
    "    \"\"\"\n",
    "    arguments = {'train_file': '../MoviLabData/LEARNING_DATA/0503_total_data.csv', 'job_dir': './'}\n",
    "    train_model(**arguments)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
